<!DOCTYPE html>
<html lang="zh-Hans,en,zh_CN,default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"8.0.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content="论文题目：MobileNetV2: Inverted Residuals and Linear Bottlenecks  论文作者：Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen  相关代码：   摘要文章介绍了新的提高应用于多任务上的轻型网络；介绍了将模型应用于新的SSDLite框架上。">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读 | MobileNetV2: Inverted Residuals and Linear Bottlenecks">
<meta property="og:url" content="http://yoursite.com/2020/03/22/Paper-Reading-MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks/index.html">
<meta property="og:site_name" content="光">
<meta property="og:description" content="论文题目：MobileNetV2: Inverted Residuals and Linear Bottlenecks  论文作者：Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen  相关代码：   摘要文章介绍了新的提高应用于多任务上的轻型网络；介绍了将模型应用于新的SSDLite框架上。">
<meta property="og:locale">
<meta property="og:image" content="http://yoursite.com/2020/03/22/images/WeChat4eb7cdd4b44c8b20f6faf2b555ce73bd.png">
<meta property="og:image" content="http://yoursite.com/2020/03/22/images/WeChat074088d60cf01039ba1c53485f6501e3.png">
<meta property="og:image" content="http://yoursite.com/Library/Application%20Support/typora-user-images/Note%20Mar%2021,%202020.jpeg">
<meta property="og:image" content="http://yoursite.com/2020/03/22/images/WeChataaa246c8741887d8fbbff94070344cdd.png">
<meta property="article:published_time" content="2020-03-22T00:50:21.000Z">
<meta property="article:modified_time" content="2020-03-22T00:50:21.000Z">
<meta property="article:author" content="Chenxi">
<meta property="article:tag" content="图像分割">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/03/22/images/WeChat4eb7cdd4b44c8b20f6faf2b555ce73bd.png">


<link rel="canonical" href="http://yoursite.com/2020/03/22/Paper-Reading-MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>论文阅读 | MobileNetV2: Inverted Residuals and Linear Bottlenecks | 光</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="光" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">光</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Life sucks, but you're gonna love it.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">2.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0"><span class="nav-number">3.</span> <span class="nav-text">相关文章</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%9D%E6%9C%9F%E5%B7%A5%E4%BD%9C%EF%BC%8C%E8%AE%A8%E8%AE%BA%E5%92%8C%E7%9B%B4%E8%A7%89%E8%AE%BE%E8%AE%A1"><span class="nav-number">4.</span> <span class="nav-text">初期工作，讨论和直觉设计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Depthwise-Seperable-Convolution"><span class="nav-number">4.1.</span> <span class="nav-text">Depthwise Seperable Convolution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-Bottleneck"><span class="nav-number">4.2.</span> <span class="nav-text">Linear Bottleneck</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%80%92%E7%BD%AE%E6%AE%8B%E5%B7%AE"><span class="nav-number">4.3.</span> <span class="nav-text">倒置残差</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E6%B5%81"><span class="nav-number">4.4.</span> <span class="nav-text">信息流</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Model-Architecture"><span class="nav-number">5.</span> <span class="nav-text">Model Architecture</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Implementation-Notes"><span class="nav-number">6.</span> <span class="nav-text">Implementation Notes</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Memory-efficient-inference"><span class="nav-number">6.1.</span> <span class="nav-text">Memory efficient inference</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bottleneck-Residual-Block"><span class="nav-number">6.2.</span> <span class="nav-text">Bottleneck Residual Block</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiments"><span class="nav-number">7.</span> <span class="nav-text">Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ImageNet-%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="nav-number">7.1.</span> <span class="nav-text">ImageNet 分类任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Object-Detection"><span class="nav-number">7.2.</span> <span class="nav-text">Object Detection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Semantic-Segmentation"><span class="nav-number">7.3.</span> <span class="nav-text">Semantic Segmentation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">8.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Author</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">52</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/22/Paper-Reading-MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Author">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="光">
    </span>

    
    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          论文阅读 | MobileNetV2: Inverted Residuals and Linear Bottlenecks
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-03-22 08:50:21" itemprop="dateCreated datePublished" datetime="2020-03-22T08:50:21+08:00">2020-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <ul>
<li><p>论文题目：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p>
</li>
<li><p>论文作者：<a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandler%2C+M">Mark Sandler</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howard%2C+A">Andrew Howard</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+M">Menglong Zhu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhmoginov%2C+A">Andrey Zhmoginov</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Liang-Chieh Chen</a></p>
</li>
<li><p>相关代码：</p>
</li>
</ul>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>文章介绍了新的提高应用于多任务上的轻型网络；介绍了将模型应用于新的SSDLite框架上。这个模型是基于倒置残差结构； 发现移除比较narrow的神经网络层中的非线性比较重要。分别在分类和目标检测的任务上做了实验。</p>
<p>【这篇文章主要提出的是inverted bottleneck结构和结构中线性的加入，都是为了在传播过程中可以最大化保留输入数据的信息】</p>
<a id="more"></a>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>神经网络被运用在很多需要人工智能技术的地方，并且能够很好的提升实现任务的效率和精度。然而这些的前提是需要有大量的计算资源，如果希望将这些模型应用于手机一些计算资源匮乏的设备，那么将会收到很大的限制。本篇文章介绍了一种新的轻型网络计算机视觉模型，可以用在手机等移动设备上并且保持同样的准确率。</p>
<p>本篇文章的主要贡献是新型的网络模块：inverted residual linear bottleneck 【转置残差线性的bottleneck结构，其实看了结构之后就很好理解他的名称了】。模块的输入是低维度的压缩特征，在经过模块时先被拓展到高维然后经过轻型卷积。之后特征在线性卷积后被投射回低纬度。<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet">Tensoflow-slim库中有官方的应用</a>。</p>
<h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><ul>
<li>近来有很多模型的设计都提高了任务的准确度 AlexNet, VGGNet, GoogLeNet, ResNet</li>
<li>也有很多对训练超参的优化</li>
<li>还有一些文章提出对网络结构模块内部链接进行改造 ShuffleNet, 或者引入稀疏性</li>
<li>进来还有一些利用集中于遗传网络和强化学习进行网络搜索的方法。</li>
</ul>
<p>在本篇文章中，我们理智于构建一个简单而高效的网络，本网络的构建是基于MobileNetV1完成的，在提升精度的前提下，保持了网络建构的简单并且不需要引入其他的特殊的操作。</p>
<h1 id="初期工作，讨论和直觉设计"><a href="#初期工作，讨论和直觉设计" class="headerlink" title="初期工作，讨论和直觉设计"></a>初期工作，讨论和直觉设计</h1><h2 id="Depthwise-Seperable-Convolution"><a href="#Depthwise-Seperable-Convolution" class="headerlink" title="Depthwise Seperable Convolution"></a>Depthwise Seperable Convolution</h2><p>深度分离卷积最基本的想法就是将一个全连接卷及操作划分为两步卷积操作，在这两步操作之下可以大大减少卷积的参数。</p>
<p>两步操作如下：</p>
<ol>
<li><p>Depthwise Convolution</p>
<p>深度卷积这个叫法说起来很泛泛，但实际上很好理解。就是对输入的的每一层channel进行一个卷积操作。在标准的卷及操作中，一个 $h_i\times w_i\times d_i$ 的输入，经过一个 $k\times k\times d_i\times d_j$ 的kernel之后，（在适当的padding下），会生成一个 $h_i\times w_i\times d_j$ 的输出。【$d_j$ 是卷积kernel的个数】，简化一下来说，在标准的卷积操作中，在和一个 $k\times k\times d_i$ 的kernel做卷积后的结果会是  $h_i\times w_i\times 1$ 的特征。</p>
<p>但是在深度卷积操作中， $k\times k\times d_i$ 这个kernel中的每一层分别对 $h_i\times w_i\times d_i$ 的每一层进行卷积，就可以得到一个 $h_i\times w_i\times d_i$ 的结果， 所以少了很多乘法的操作。</p>
<p>【可以理解为我们现在有$d_i$ 个 $k\times k \times 1$ 的kernel，其中每一个kernel分别对$h_i\times w_i\times d_i$ 中的每一层进行卷积，然后再排列在一起】</p>
</li>
<li><p>Pointwise Convolution</p>
<p>那既然通过之前的一步产生了 $h_i\times w_i\times d_i$ 的特征，那么这一步就通过 $d_j$ 个 $1\times 1\times d_i$ 的kernel，对将它变为 $h_i\times w_i\times d_j$ 维。这一步其实是对之前产生的特征进行组合。</p>
</li>
</ol>
<p>在标准的卷积操作下，得到一个  $h_i\times w_i\times d_j$ 的特征需要的乘法操作是: $k\times k\times d_i \times(h_i \times w_i) \times d_j$ 【这里基本按照卷积操作顺序写的，每一次卷积需要做$k\times k\times d_i$ 次乘法，一共做$h_i \times w_i$ 次，一共有 $d_j$ 个kernel】</p>
<p>在深度卷积网络下，得到一个  $h_i\times w_i\times d_j$ 的特征时需要的乘法操作是：$k \times k\times h_i\times w_i\times d_i$【depthwise】+ $h_i\times w_i\times d_i \times d_j$ 【pointwise】 = $h_i\times w_i\times d_i(k^2+d_j)$， 乘法减少了大概 $k^2$ 倍</p>
<h2 id="Linear-Bottleneck"><a href="#Linear-Bottleneck" class="headerlink" title="Linear Bottleneck"></a>Linear Bottleneck</h2><p>假设现在的神经网络有 $n$ 层，每一层 $L_i$ 都有一个大小为 $h_i\times w_i\times d$ 的activation tensor。这部分将讨论这些acti tensor 的基本性质。【大概是个高维的activation function ?】</p>
<p>通俗来讲，对于每一组输入的真实图片，我们说对于任意一层 $L_i$ 的层激活函数形成了“manifold of interest”。长久以来我们都假设神经网络中的“manifold of interest”可以被更低纬度的子空间来表示。也就是说，如果我们看深度卷积中某一层的d-channel的tensor，信息是隐藏在某些manifold中的，也就是说我们可以用子空间来表示这些（有效）信息。</p>
<p>简单来说，实现这个目标可以通过降维来实现。MobileNetv1的时候就用过一个width multiplier参数实现了部分的提升。根据这个width multiplier带来的启发，我们可以将激活空间降维直到“manifold of interest”布满整个空间。然而这个操作被神经网络做存在的非线性ReLu给打断了。在一维空间中，ReLu会产生一个射线状的形状；在高维空间中ReLu会变成有n个节点的分段线性曲线。<img src="../images/WeChat4eb7cdd4b44c8b20f6faf2b555ce73bd.png" alt="WeChat4eb7cdd4b44c8b20f6faf2b555ce73bd"></p>
<p>这里举的这个ReLu的例子，我觉得是这样。</p>
<ul>
<li>一方面是说非零部分的信息会保留的比较完整，这说明了ReLu的线性部分可以保留输入的全部信息。</li>
<li>另一方面是为了说明在高维加入非线性会对传递的信息造成影响，在高维丢失的信息可以在重新投射回低维空间后看的更加明显。于是举例说明了一个二维螺旋线的输入，分别在升维之后通过非线性ReLu方程后，再重新降维至本来的低维空间时的二维螺旋线。可以看到，ReLu非线性对这些螺旋线在某些channel上会有影响，也就是造成了信息损失。然而当我们升维的channel数越多（升维越高），信息在某些channel被保留住的可能性就越大。也就是说，当我们的输入manifold 可以再某个特定的subspace保留并且不受到ReLu的影响。</li>
</ul>
<p>这样的话就总结出来了 “manifold of interest” 应该被投射在高维激活空间的某个低维子空间内。</p>
<ul>
<li>如果 “manifold of interest” 在经过ReLu之后仍旧是非零的，那么这部分是由ReLu中的Linear部分产生的；</li>
<li>只有当输入manifold存在于输入的低维子空间时， ReLu可以保留输入manifold完整的信息。</li>
</ul>
<p>由这两点，我们就可以得出优化现在神经网络结构的hints：</p>
<p>若“manifold of interest”是存在于低维地空间的话，我们可以通过在卷积模块中加入线性的bottleneck结构来捕捉这个信息</p>
<h2 id="倒置残差"><a href="#倒置残差" class="headerlink" title="倒置残差"></a>倒置残差</h2><p>bottleneck block 和 residual block结构是类似的，每一个block的输入都会跟随一些bottleneck 然后是一些展开模块。经典的残差结构和倒置残差结构。经典的残差模型是将bottle部分比较厚的地方连接起来，但是倒置的残差网络是把bottle neck连接起来。【这部分应该就是应景之前传递的时候要将特征变到高维之后再使用非线性】</p>
<p><img src="../images/WeChat074088d60cf01039ba1c53485f6501e3.png" alt="WeChat074088d60cf01039ba1c53485f6501e3"></p>
<h2 id="信息流"><a href="#信息流" class="headerlink" title="信息流"></a>信息流</h2><p>这部分好像也没说啥内容</p>
<h1 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h1><p>这部分更加细节介绍网络结构的每个模块。</p>
<p>这是一个由channel数 $k$ 变为$k’$ 的，expansion系数为 $t$ 的Bottleneck residual block的具体形式：</p>
<p><img src="../../../../Library/Application%20Support/typora-user-images/Note%20Mar%2021,%202020.jpeg" alt="Note Mar 21, 2020"></p>
<p>整体的网络结构如下：</p>
<p><img src="../images/WeChataaa246c8741887d8fbbff94070344cdd.png" alt="WeChataaa246c8741887d8fbbff94070344cdd"></p>
<ul>
<li>kernel size的大小一般都是标准的 $3\times 3$</li>
<li>也会用到dropout和batchnorm</li>
<li>拓展倍数expansion rate 常数设置在 5-10之间得到的结果都差不多，对于大一点的网络，用的系数会大一些，小的网络用到的系数小</li>
<li>对除了最后一层的所有层都用到了width mutiplier</li>
</ul>
<h1 id="Implementation-Notes"><a href="#Implementation-Notes" class="headerlink" title="Implementation Notes"></a>Implementation Notes</h1><h2 id="Memory-efficient-inference"><a href="#Memory-efficient-inference" class="headerlink" title="Memory efficient inference"></a>Memory efficient inference</h2><p>(这部分大概在说计算资源？)</p>
<h2 id="Bottleneck-Residual-Block"><a href="#Bottleneck-Residual-Block" class="headerlink" title="Bottleneck Residual Block"></a>Bottleneck Residual Block</h2><p>（这部分再说用了residual block之后计算量减少了很多）</p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="ImageNet-分类任务"><a href="#ImageNet-分类任务" class="headerlink" title="ImageNet 分类任务"></a>ImageNet 分类任务</h2><ul>
<li>RMSPropOptimizer decay = 0.9， momentum = 0.9</li>
<li>BatchNorm，standard weight decay 是0.00004</li>
<li>Learning rate是0.045， learning rate decay 是每个epoch下降0.98</li>
</ul>
<h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><ul>
<li>SSDLite：SSD结构中的标准卷积都替换为深度分离卷积。</li>
</ul>
<h2 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h2><ul>
<li>MobileNetV2 被当做是 DeepLabV3中的特征提取部分</li>
<li>有以不同的发现：<ul>
<li>添加不同尺度，包括添加左右翻转的图片不适合移动设备的应用</li>
<li>output_stride = 16的效果更好</li>
<li>MobileNetV1作为特征提取的框架已经很好了</li>
<li>在MobileNetV2的倒数第二层连接 DeepLabV3的分割头效果比直接连在最后一层好，因为他有320个channel</li>
<li>DeepLabV3分割头真的很消耗时间，去除ASPP部分可以省下很多时间并且准确度不会下降很多</li>
</ul>
</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这篇文章主要就是提出在神经网络操作过程中如何保留更多的信息。最主要的一点自然是：inverted residual with linear bottleneck 了。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/" rel="tag"># 图像分割</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/03/20/Machine-Learning-2020-Lecture-0-Introduction/" rel="prev" title="Machine Learning-2020| Lecture#0 Introduction">
                  <i class="fa fa-chevron-left"></i> Machine Learning-2020| Lecture#0 Introduction
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/03/23/PaperReading-MobileNetsV1/" rel="next" title="论文阅读 | MobileNets - Efﬁcient Convolutional Neural Networks for Mobile Vision Applications">
                  论文阅读 | MobileNets - Efﬁcient Convolutional Neural Networks for Mobile Vision Applications <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
  
  
  



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Author</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  















  








  

  

</body>
</html>
